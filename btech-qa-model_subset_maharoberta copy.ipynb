{"cells":[{"cell_type":"markdown","metadata":{},"source":["Import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T12:44:55.585718Z","iopub.status.busy":"2024-11-03T12:44:55.585275Z","iopub.status.idle":"2024-11-03T12:45:20.021226Z","shell.execute_reply":"2024-11-03T12:45:20.020217Z","shell.execute_reply.started":"2024-11-03T12:44:55.585676Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\cl502_19\\Desktop\\Domain-LLM\\LLMProj\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n","from transformers import Trainer, TrainingArguments\n","from datasets import DatasetDict, load_dataset"]},{"cell_type":"markdown","metadata":{},"source":["Load Dataset and Model"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T12:45:52.705020Z","iopub.status.busy":"2024-11-03T12:45:52.704605Z","iopub.status.idle":"2024-11-03T12:46:23.499579Z","shell.execute_reply":"2024-11-03T12:46:23.498480Z","shell.execute_reply.started":"2024-11-03T12:45:52.704978Z"},"trusted":true},"outputs":[],"source":["dataset = load_dataset(\"json\", data_files={\n","    \"train\": \"mahasquad\\\\train.json\",\n","    \"validation\": \"mahasquad\\\\val.json\",\n","    \"test\": \"mahasquad\\\\test.json\"\n","})"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-03T12:46:23.501452Z","iopub.status.busy":"2024-11-03T12:46:23.501008Z","iopub.status.idle":"2024-11-03T12:48:24.501303Z","shell.execute_reply":"2024-11-03T12:48:24.499184Z","shell.execute_reply.started":"2024-11-03T12:46:23.501403Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\cl502_19\\Desktop\\Domain-LLM\\LLMProj\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at l3cube-pune/marathi-roberta and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Load the XLM-R tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(\"l3cube-pune/marathi-roberta\")\n","model = AutoModelForQuestionAnswering.from_pretrained(\"l3cube-pune/marathi-roberta\")"]},{"cell_type":"markdown","metadata":{},"source":["Preprocessing function"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['data'],\n","        num_rows: 118516\n","    })\n","    validation: Dataset({\n","        features: ['data'],\n","        num_rows: 11873\n","    })\n","    test: Dataset({\n","        features: ['data'],\n","        num_rows: 11803\n","    })\n","})\n","{'data': {'answers': {'answer_start': [], 'text': []}, 'context': 'प्रेस्बिटेरियनिझम हा उत्तर आयर्लंडमधील सर्वात मोठा प्रोटेस्टंट संप्रदाय आहे आणि आयर्लंड बेटावर (आयर्लंडच्या अँग्लिकन चर्च नंतर) दुसरा सर्वात मोठा संप्रदाय आहे, [उद्धरण आवश्यक आहे] आणि स्कॉटिश वृक्षारोपण स्थायिकांनी अल्स्टरमध्ये आणले होते ज्यांना जेम्स व्ही द्वारे स्थलांतर करण्यास जोरदार प्रोत्साहन दिले होते. स्कॉटलंडचा, नंतर इंग्लंडचा जेम्स पहिला. अंदाजे १००,००० स्कॉटिश प्रेस्बिटेरियन्स १६०७ आणि १६९० मध्ये बॉयनच्या लढाईदरम्यान आयर्लंडच्या उत्तरेकडील काउंटीजमध्ये स्थलांतरित झाले. अल्स्टर आणि उर्वरित आयर्लंडमधील रोमन कॅथोलिकांसह प्रेस्बिटेरियन, १९व्या शतकाच्या सुरुवातीस ते मागे घेण्यापर्यंत भेदभाव करणाऱ्या दंड कायद्यांतर्गत त्रास सहन करावा लागला. आयर्लंडमधील प्रेस्बिटेरियन चर्च, अल्स्टरचे फ्री प्रेस्बिटेरियन चर्च, आयर्लंडचे नॉन-सबस्क्राइबिंग प्रेस्बिटेरियन चर्च, आयर्लंडचे रिफॉर्म्ड प्रेस्बिटेरियन चर्च आणि इव्हॅन्जेलिकल प्रेस्बिटेरियन चर्च यांनी आयर्लंडमध्ये प्रेस्बिटेरियनवादाचे प्रतिनिधित्व केले आहे.', 'id': '5acfd57077cf76001a68625a', 'question': 'उत्तर आयर्लंडमध्ये कोणता धर्म दुसरा सर्वात मोठा संप्रदाय आहे?', 'title': 'प्रेस्बिटेरियनवाद'}}\n"]}],"source":["print(dataset)\n","print(dataset[\"train\"][0])"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.status.busy":"2024-11-03T12:48:24.502626Z","iopub.status.idle":"2024-11-03T12:48:24.503796Z","shell.execute_reply":"2024-11-03T12:48:24.503474Z","shell.execute_reply.started":"2024-11-03T12:48:24.503439Z"},"trusted":true},"outputs":[],"source":["def preprocess_data(examples):\n","    questions = [item[\"question\"] for item in examples[\"data\"]]\n","    contexts = [item[\"context\"] for item in examples[\"data\"]]\n","    answers = [item[\"answers\"] for item in examples[\"data\"]]\n","\n","    # Tokenize the inputs with truncation and padding\n","    inputs = tokenizer(\n","        questions,\n","        contexts,\n","        max_length=384,\n","        truncation=True,\n","        padding=\"max_length\",\n","        return_tensors=\"pt\"\n","    )\n","\n","    start_positions = []\n","    end_positions = []\n","\n","    for i, ans in enumerate(answers):\n","        if ans[\"answer_start\"]:\n","            start = ans[\"answer_start\"][0]\n","            end = start + len(ans[\"text\"][0])\n","            # Adjust start and end based on tokenized input\n","            start_positions.append(start)\n","            end_positions.append(end)\n","        else:\n","            start_positions.append(0)\n","            end_positions.append(0)\n","\n","    inputs[\"start_positions\"] = start_positions\n","    inputs[\"end_positions\"] = end_positions\n","    return inputs\n"]},{"cell_type":"markdown","metadata":{},"source":["Take subset of dataset"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train subset size: 1185\n","Validation subset size: 118\n","Test subset size: 118\n"]}],"source":["# Set a fraction of the dataset to use\n","fraction = 0.01  # Use 1% of the dataset\n","\n","# Shuffle and select a subset of the training, validation, and test sets\n","train_subset = dataset[\"train\"].shuffle(seed=42).select(range(int(len(dataset[\"train\"]) * fraction)))\n","validation_subset = dataset[\"validation\"].shuffle(seed=42).select(range(int(len(dataset[\"validation\"]) * fraction)))\n","test_subset = dataset[\"test\"].shuffle(seed=42).select(range(int(len(dataset[\"test\"]) * fraction)))\n","\n","# Create a new DatasetDict with the subsets\n","subset_dataset = DatasetDict({\n","    \"train\": train_subset,\n","    \"validation\": validation_subset,\n","    \"test\": test_subset\n","})\n","\n","# Check the sizes of the subsets to confirm\n","print(f\"Train subset size: {len(subset_dataset['train'])}\")\n","print(f\"Validation subset size: {len(subset_dataset['validation'])}\")\n","print(f\"Test subset size: {len(subset_dataset['test'])}\")"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","\n","\u001b[A\u001b[A\n","\n","\u001b[A\u001b[A\n","\n","Map: 100%|██████████| 1185/1185 [00:01<00:00, 893.41 examples/s]\n","\n","\n","\u001b[A\u001b[A\n","\n","Map: 100%|██████████| 118/118 [00:00<00:00, 756.30 examples/s]\n","\n","\n","\u001b[A\u001b[A\n","\n","Map: 100%|██████████| 118/118 [00:00<00:00, 700.56 examples/s]\n"]}],"source":["# Proceed with tokenization and training using subset_dataset\n","tokenized_subset = subset_dataset.map(preprocess_data, batched=True)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['data', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n","        num_rows: 1185\n","    })\n","    validation: Dataset({\n","        features: ['data', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n","        num_rows: 118\n","    })\n","    test: Dataset({\n","        features: ['data', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n","        num_rows: 118\n","    })\n","})\n"]}],"source":["print(tokenized_subset)"]},{"cell_type":"markdown","metadata":{},"source":["Evaluation parameter"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["import evaluate\n","import numpy as np\n","\n","# Load evaluation metrics\n","metric = evaluate.load(\"squad_v2\")\n","\n","def compute_metrics(eval_pred):\n","    predictions, references = eval_pred\n","    start_logits, end_logits = predictions\n","    start_predictions = np.argmax(start_logits, axis=1)\n","    end_predictions = np.argmax(end_logits, axis=1)\n","    return metric.compute(predictions={\"id\": start_predictions, \"end\": end_predictions}, references=references)"]},{"cell_type":"markdown","metadata":{},"source":["Training Arguments and Trainer"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./qa_subset_maharoberta_1_results\",\n","    eval_strategy=\"epoch\",\n","    learning_rate=3e-5,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    log_level='debug',\n","    logging_steps=10,\n",")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# Initialize Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_subset[\"train\"],\n","    eval_dataset=tokenized_subset[\"validation\"],\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Training the model"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/447 [3:40:09<?, ?it/s]\n","Currently training with a batch size of: 8\n","The following columns in the training set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: data. If data are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n","***** Running training *****\n","  Num examples = 1,185\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 447\n","  Number of trainable parameters = 277,454,594\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","                                                  \n","\u001b[A                                                  \n","\n","  2%|▏         | 10/447 [09:23<7:17:43, 60.10s/it]\n","\u001b[A"]},{"name":"stdout","output_type":"stream","text":["{'loss': 3.4466, 'grad_norm': 14.770986557006836, 'learning_rate': 2.9328859060402686e-05, 'epoch': 0.07}\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \n","\u001b[A                                                  \n","\n","  4%|▍         | 20/447 [19:55<7:33:42, 63.75s/it]\n","\u001b[A"]},{"name":"stdout","output_type":"stream","text":["{'loss': 3.5451, 'grad_norm': 5.7172417640686035, 'learning_rate': 2.8657718120805368e-05, 'epoch': 0.13}\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \n","\u001b[A                                                  \n","\n","  7%|▋         | 30/447 [29:58<7:08:24, 61.64s/it]\n","\u001b[A"]},{"name":"stdout","output_type":"stream","text":["{'loss': 3.7508, 'grad_norm': 3.39996600151062, 'learning_rate': 2.7986577181208053e-05, 'epoch': 0.2}\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \n","\u001b[A                                                  \n","\n","  9%|▉         | 40/447 [40:30<7:16:32, 64.36s/it]\n","\u001b[A"]},{"name":"stdout","output_type":"stream","text":["{'loss': 3.7231, 'grad_norm': 3.0733251571655273, 'learning_rate': 2.731543624161074e-05, 'epoch': 0.27}\n"]},{"name":"stderr","output_type":"stream","text":["                                                  \n","\u001b[A                                                  \n","\n"," 11%|█         | 50/447 [50:42<6:41:43, 60.71s/it]\n","\u001b[A"]},{"name":"stdout","output_type":"stream","text":["{'loss': 3.3397, 'grad_norm': 6.282351970672607, 'learning_rate': 2.6644295302013424e-05, 'epoch': 0.34}\n"]},{"name":"stderr","output_type":"stream","text":["                                                    \n","\u001b[A                                                  \n","\n"," 13%|█▎        | 60/447 [1:00:52<6:31:39, 60.72s/it]\n","\u001b[A"]},{"name":"stdout","output_type":"stream","text":["{'loss': 3.039, 'grad_norm': 2.734901189804077, 'learning_rate': 2.5973154362416106e-05, 'epoch': 0.4}\n"]},{"name":"stderr","output_type":"stream","text":["                                                    \n","\u001b[A                                                  \n","\n"," 16%|█▌        | 70/447 [1:11:21<6:41:51, 63.96s/it]\n","\u001b[A"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.8886, 'grad_norm': 5.130919456481934, 'learning_rate': 2.530201342281879e-05, 'epoch': 0.47}\n"]},{"name":"stderr","output_type":"stream","text":["                                                    \n","\u001b[A                                                  \n","\n"," 18%|█▊        | 80/447 [1:21:38<6:03:57, 59.50s/it]\n","\u001b[A"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.9961, 'grad_norm': 3.7754063606262207, 'learning_rate': 2.4630872483221476e-05, 'epoch': 0.54}\n"]},{"name":"stderr","output_type":"stream","text":["                                                    \n","\u001b[A                                                  \n","\n"," 20%|██        | 90/447 [1:32:19<6:13:53, 62.84s/it]\n","\u001b[A"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.9761, 'grad_norm': 6.0506591796875, 'learning_rate': 2.3959731543624162e-05, 'epoch': 0.6}\n"]},{"name":"stderr","output_type":"stream","text":["                                                     \n","\u001b[A                                                  \n","\n"," 22%|██▏       | 100/447 [1:42:43<5:47:56, 60.16s/it]\n","\u001b[A"]},{"name":"stdout","output_type":"stream","text":["{'loss': 3.4547, 'grad_norm': 7.94872522354126, 'learning_rate': 2.3288590604026844e-05, 'epoch': 0.67}\n"]},{"name":"stderr","output_type":"stream","text":["                                                     \n","\u001b[A                                                  \n","\n"," 25%|██▍       | 110/447 [1:53:11<5:47:24, 61.85s/it]\n","\u001b[A"]},{"name":"stdout","output_type":"stream","text":["{'loss': 3.4749, 'grad_norm': 4.710449695587158, 'learning_rate': 2.261744966442953e-05, 'epoch': 0.74}\n"]},{"name":"stderr","output_type":"stream","text":["                                                     \n","\u001b[A                                                  \n","\n"," 27%|██▋       | 120/447 [2:03:33<5:40:40, 62.51s/it]\n","\u001b[A"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.788, 'grad_norm': 6.004735946655273, 'learning_rate': 2.1946308724832218e-05, 'epoch': 0.81}\n"]},{"name":"stderr","output_type":"stream","text":["                                                     \n","\u001b[A                                                  \n","\n"," 29%|██▉       | 130/447 [2:13:57<5:30:20, 62.53s/it]\n","\u001b[A"]},{"name":"stdout","output_type":"stream","text":["{'loss': 2.9261, 'grad_norm': 10.497357368469238, 'learning_rate': 2.1275167785234903e-05, 'epoch': 0.87}\n"]},{"name":"stderr","output_type":"stream","text":["                                                     \n","\u001b[A                                                  \n","\n"," 31%|███▏      | 140/447 [2:24:20<5:18:10, 62.18s/it]\n","\u001b[A"]},{"name":"stdout","output_type":"stream","text":["{'loss': 4.2114, 'grad_norm': 4.02404260635376, 'learning_rate': 2.0604026845637585e-05, 'epoch': 0.94}\n"]},{"name":"stderr","output_type":"stream","text":[" 33%|███▎      | 149/447 [2:33:15<4:27:09, 53.79s/it]The following columns in the evaluation set don't have a corresponding argument in `XLMRobertaForQuestionAnswering.forward` and have been ignored: data. If data are not expected by `XLMRobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 118\n","  Batch size = 8\n","\n","\n","\u001b[A\u001b[A\n","\n","\u001b[A\u001b[A\n","\n","\u001b[A\u001b[A\n","\n","\u001b[A\u001b[A\n","\n","\u001b[A\u001b[A\n","\n","\u001b[A\u001b[A\n","\n","\u001b[A\u001b[A\n","\n","\u001b[A\u001b[A\n","\n","\u001b[A\u001b[A\n","\n","\u001b[A\u001b[A\n","\n","\u001b[A\u001b[A\n","\n","\u001b[A\u001b[A\n","\n","\u001b[A\u001b[A\n","\n","\u001b[A\u001b[A\n","\n","\u001b[A\u001b[A"]},{"ename":"KeyError","evalue":"0","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\cl502_19\\Desktop\\Domain-LLM\\LLMProj\\Lib\\site-packages\\transformers\\trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\cl502_19\\Desktop\\Domain-LLM\\LLMProj\\Lib\\site-packages\\transformers\\trainer.py:2376\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2375\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 2376\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[0;32m   2379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[0;32m   2380\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\cl502_19\\Desktop\\Domain-LLM\\LLMProj\\Lib\\site-packages\\transformers\\trainer.py:2804\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2802\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[1;32m-> 2804\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m   2807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_checkpoint(model, trial, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n","File \u001b[1;32mc:\\Users\\cl502_19\\Desktop\\Domain-LLM\\LLMProj\\Lib\\site-packages\\transformers\\trainer.py:2761\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[1;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[0;32m   2760\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m-> 2761\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[0;32m   2764\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\cl502_19\\Desktop\\Domain-LLM\\LLMProj\\Lib\\site-packages\\transformers\\trainer.py:3666\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3663\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   3665\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 3666\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3667\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3669\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   3670\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   3671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3674\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3676\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   3677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n","File \u001b[1;32mc:\\Users\\cl502_19\\Desktop\\Domain-LLM\\LLMProj\\Lib\\site-packages\\transformers\\trainer.py:3956\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3952\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[0;32m   3953\u001b[0m             EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, inputs\u001b[38;5;241m=\u001b[39mall_inputs)\n\u001b[0;32m   3954\u001b[0m         )\n\u001b[0;32m   3955\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3956\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3958\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n","Cell \u001b[1;32mIn[20], line 12\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[1;34m(eval_pred)\u001b[0m\n\u001b[0;32m     10\u001b[0m start_predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(start_logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m end_predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(end_logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_predictions\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreferences\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\cl502_19\\Desktop\\Domain-LLM\\LLMProj\\Lib\\site-packages\\evaluate\\module.py:455\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[1;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[0;32m    452\u001b[0m compute_kwargs \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m--> 455\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finalize()\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\cl502_19\\Desktop\\Domain-LLM\\LLMProj\\Lib\\site-packages\\evaluate\\module.py:519\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[1;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, column \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(column) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 519\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enforce_nested_string_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_feature_format[key], \u001b[43mcolumn\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    520\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_feature_format\u001b[38;5;241m.\u001b[39mencode_batch(batch)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39mwrite_batch(batch)\n","\u001b[1;31mKeyError\u001b[0m: 0"]}],"source":["# Train the model\n","trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["Saving the model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save the fine-tuned model\n","model.save_pretrained(\"marathi-qa-20-mahasquad\")\n","tokenizer.save_pretrained(\"marathi-qa-20-mahasquad\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5999213,"sourceId":9790547,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":4}
